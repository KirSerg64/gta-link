{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script takes in tracking results in MOT format for sequence and visualize cropped instances of individual targets from different frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\Ciel Sun\\OneDrive - UW\\EE 599\\TrackLink\\reid\\torchreid\\utils\")\n",
    "from feature_extractor import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|██████████| 1126/1126 [00:25<00:00, 43.84it/s]\n"
     ]
    }
   ],
   "source": [
    "res_path = r\"C:\\Users\\Ciel Sun\\OneDrive - UW\\EE 599\\SportsMOT\\Sort_Results\\Sort_Baseline\\v_6OLC1-bhioc_c001.txt\" # path to tracking results\n",
    "\n",
    "seq_name = os.path.basename(res_path).split(\".txt\")[0]\n",
    "# seq_data_dir = r\"C:\\Users\\Ciel Sun\\OneDrive - UW\\EE 599\\SoccerNet\\tracking-2023\\test\\SNMOT-116\" # path to specific sequence with directories img1, dets, gt\n",
    "# data_dir = r\"C:\\Users\\Ciel Sun\\OneDrive - UW\\EE 599\\SoccerNet\\tracking-2023\\test\"\n",
    "data_dir = r\"C:\\Users\\Ciel Sun\\OneDrive - UW\\EE 599\\SportsMOT\\dataset\\test\"\n",
    "split = os.path.basename(data_dir)\n",
    "assert split in (\"train\", \"test\", \"challenge\")\n",
    "seq_data_dir = os.path.join(data_dir, seq_name)\n",
    "img_dir = os.path.join(seq_data_dir, \"img1\")\n",
    "split = os.path.basename(split)\n",
    "if \"SoccerNet\" in seq_data_dir:\n",
    "    dataset = \"SoccerNet\"\n",
    "elif \"SportsMOT\" in seq_data_dir:\n",
    "    dataset = \"SportsMOT\"\n",
    "else:\n",
    "    dataset = None\n",
    "assert dataset in (\"SoccerNet\", \"SportsMOT\")\n",
    "# save_dir = os.path.join(seq_data_dir, \"..\", \"..\", \"_temp\", f\"visualization\", seq_name) # create path to save directory, vizualiation->seq_name\n",
    "save_dir = os.path.join(\"..\", \"_temp\", \"visualization\", dataset, seq_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "# TODO: \n",
    "# load tracking resutls in dataframe\n",
    "# for each image frame in img1:\n",
    "#   query results for the frame\n",
    "#   create folder for each new track id\n",
    "#   save cropped image of target in track id folder, save the file with the same name as image(i.e.f'{frame_id}.jpg')\n",
    "track_res = np.genfromtxt(res_path, dtype=float, delimiter=',')\n",
    "# NOTE: MOT format <frame>, <id>, <bb_left>, <bb_top>, <bb_width>, <bb_height>, <conf>, <x>, <y>, <z>\n",
    "\n",
    "max_frame_id = int(np.max(track_res[:, 0]))\n",
    "\n",
    "for frame_id in tqdm(range(1, max_frame_id + 1), desc=\"Processing Frames\"):\n",
    "    img_fname = f\"{frame_id:06d}.jpg\"\n",
    "    img_path = os.path.join(img_dir, img_fname)\n",
    "    img = Image.open(img_path)\n",
    "    frame_dets = track_res[track_res[:, 0] == frame_id]\n",
    "    # TODO:\n",
    "    # for each line of detection\n",
    "    #   get track_id, create folder save_dir + {track_id}\n",
    "    #   crop instance and save to created folder with img_fname\n",
    "    seen_tid = set()\n",
    "    for _, track_id, l, t, w, h, _, _, _, _ in frame_dets:\n",
    "        \n",
    "        tid_dir = os.path.join(save_dir, f\"{track_id:.0f}\")\n",
    "        if track_id not in seen_tid:\n",
    "            os.makedirs(tid_dir, exist_ok=True)\n",
    "            seen_tid.add(track_id)\n",
    "        instance_im = img.crop((l, t, l+w, t+h))\n",
    "        # save the instance_im\n",
    "        instance_im.save(os.path.join(tid_dir, img_fname))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code below takes in image instances of one resulting tracklet and calculates inner cosine distance of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded pretrained weights from \"C:\\Users\\Ciel Sun\\OneDrive - UW\\EE 599\\TrackLink\\checkpoints\\sports_model.pth.tar-60\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "(513, 512)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 113\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(embs)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    112\u001b[0m average_distance \u001b[38;5;241m=\u001b[39m get_avg_inner_distance(embs)\n\u001b[1;32m--> 113\u001b[0m id_switch_detected, clusters \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_id_switch\u001b[49m\u001b[43m(\u001b[49m\u001b[43membs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Inner Distance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage_distance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentity Switch Detected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_switch_detected\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[108], line 80\u001b[0m, in \u001b[0;36mdetect_id_switch\u001b[1;34m(embs, eps, min_samples, max_clusters)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Find the closest pair of clusters\u001b[39;00m\n\u001b[0;32m     79\u001b[0m min_dist_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munravel_index(np\u001b[38;5;241m.\u001b[39margmin(distance_matrix), distance_matrix\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 80\u001b[0m cluster_to_merge_1, cluster_to_merge_2 \u001b[38;5;241m=\u001b[39m \u001b[43munique_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmin_dist_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, unique_labels[min_dist_idx[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Merge the clusters\u001b[39;00m\n\u001b[0;32m     83\u001b[0m labels[labels \u001b[38;5;241m==\u001b[39m cluster_to_merge_2] \u001b[38;5;241m=\u001b[39m cluster_to_merge_1\n",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def get_avg_inner_distance(embs):\n",
    "    \"\"\"\n",
    "    Calculates the average inner cosine distance for a set of embeddings. This measure assesses the\n",
    "    compactness or consistency of the embeddings within a tracklet, helping to decide if the tracklet\n",
    "    should be split.\n",
    "\n",
    "    This function is designed to handle large sets of embeddings efficiently. If the number of embeddings\n",
    "    exceeds a certain threshold (e.g., 15,000), the embeddings are subsampled to fit within memory constraints\n",
    "    before calculating the distance.\n",
    "\n",
    "    Args:\n",
    "        embs (list of numpy arrays): A list where each element is a numpy array representing an embedding.\n",
    "                                     Each embedding has the same dimensionality.\n",
    "\n",
    "    Returns:\n",
    "        float: The average cosine distance between all pairs of embeddings in the list.\n",
    "    \"\"\"\n",
    "    while len(embs) > 15000: # GPU memory limit\n",
    "        embs = embs[1::2]\n",
    "    embs = np.stack(embs)\n",
    "    torch_embs = torch.from_numpy(embs).cuda()\n",
    "    torch_embs = torch.nn.functional.normalize(torch_embs, dim=1)\n",
    "    similarity_matrix = torch.matmul(torch_embs, torch_embs.t())\n",
    "    n = similarity_matrix.shape[0]\n",
    "    average_cosine_distance = 1 - (similarity_matrix.sum() - similarity_matrix.diag().sum()) / (n * (n - 1))\n",
    "    return average_cosine_distance\n",
    "def detect_id_switch(embs, eps=0.55, min_samples=1, max_clusters=3):\n",
    "    \"\"\"\n",
    "    Detects identity switches within a tracklet using clustering.\n",
    "\n",
    "    Args:\n",
    "        embs (list of numpy arrays): A list where each element is a numpy array representing an embedding.\n",
    "                                     Each embedding has the same dimensionality.\n",
    "        eps (float): The maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "        min_samples (int): The number of samples in a neighborhood for a point to be considered as a core point.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if an identity switch is detected, otherwise False.\n",
    "    \"\"\"\n",
    "    if len(embs) > 15000:\n",
    "        embs = embs[1::2]\n",
    "\n",
    "    embs = np.stack(embs)\n",
    "    \n",
    "    # Standardize the embeddings\n",
    "    scaler = StandardScaler()\n",
    "    embs_scaled = scaler.fit_transform(embs)\n",
    "\n",
    "    # Apply DBSCAN clustering\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine').fit(embs_scaled)\n",
    "    labels = db.labels_\n",
    "    \n",
    "    # Count the number of clusters (excluding noise)\n",
    "    unique_labels = np.unique(labels)\n",
    "    if -1 in unique_labels:\n",
    "        unique_labels.remove(-1)\n",
    "\n",
    "    if -1 in labels:\n",
    "        # Find the cluster centers\n",
    "        cluster_centers = np.array([embs_scaled[labels == label].mean(axis=0) for label in unique_labels])\n",
    "        \n",
    "        # Assign noise points to the nearest cluster\n",
    "        noise_indices = np.where(labels == -1)[0]\n",
    "        for idx in noise_indices:\n",
    "            distances = cdist([embs_scaled[idx]], cluster_centers, metric='cosine')\n",
    "            nearest_cluster = np.argmin(distances)\n",
    "            labels[idx] = list(unique_labels)[nearest_cluster]\n",
    "    \n",
    "    # Count the number of clusters (excluding noise)\n",
    "    n_clusters = len(set(labels))\n",
    "\n",
    "    if n_clusters > max_clusters:\n",
    "        # Merge clusters to ensure the number of clusters does not exceed max_clusters\n",
    "        while n_clusters > max_clusters:\n",
    "            cluster_centers = np.array([embs_scaled[labels == label].mean(axis=0) for label in unique_labels])\n",
    "            distance_matrix = cdist(cluster_centers, cluster_centers, metric='cosine')\n",
    "            np.fill_diagonal(distance_matrix, np.inf)  # Ignore self-distances\n",
    "            \n",
    "            # Find the closest pair of clusters\n",
    "            min_dist_idx = np.unravel_index(np.argmin(distance_matrix), distance_matrix.shape)\n",
    "            cluster_to_merge_1, cluster_to_merge_2 = unique_labels[min_dist_idx[0]], unique_labels[min_dist_idx[1]]\n",
    "\n",
    "            # Merge the clusters\n",
    "            labels[labels == cluster_to_merge_2] = cluster_to_merge_1\n",
    "            unique_labels = set(labels)\n",
    "            if -1 in unique_labels:\n",
    "                unique_labels.remove(-1)\n",
    "            n_clusters = len(unique_labels)\n",
    "\n",
    "    return n_clusters > 1, labels\n",
    "\n",
    "\n",
    "val_transforms = T.Compose([T.Resize([256, 128]),\n",
    "                            T.ToTensor(),\n",
    "                            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                            ])\n",
    "\n",
    "extractor = FeatureExtractor(model_name='osnet_x1_0',\n",
    "                            model_path = r\"C:\\Users\\Ciel Sun\\OneDrive - UW\\EE 599\\TrackLink\\checkpoints\\sports_model.pth.tar-60\",\n",
    "                            device='cuda'\n",
    "                            )\n",
    "img_dir = r\"C:\\Users\\Ciel Sun\\OneDrive - UW\\EE 599\\TrackLink\\track-link\\_temp\\visualization\\SportsMOT\\v_2BhBRkkAqbQ_c002\\4617_idsw\"\n",
    "embs = []\n",
    "for im_path in [os.path.join(img_dir, im) for im in os.listdir(img_dir) if im.endswith(\".jpg\")]:\n",
    "    im = Image.open(im_path)\n",
    "    im = val_transforms(im.convert('RGB')).unsqueeze(0)\n",
    "    features = extractor(im)\n",
    "    feat = features.cpu().detach().numpy().tolist()\n",
    "    embs += feat\n",
    "\n",
    "print(np.array(embs).shape)\n",
    "\n",
    "average_distance = get_avg_inner_distance(embs)\n",
    "id_switch_detected, clusters = detect_id_switch(embs)\n",
    "\n",
    "print(f\"Average Inner Distance: {average_distance}\")\n",
    "print(f\"Identity Switch Detected: {id_switch_detected}\")\n",
    "if id_switch_detected:\n",
    "    print(np.unique(clusters, return_counts=True))\n",
    "    print(f\"Clusters: {clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([1, 2, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrackLink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
